{"version":3,"file":"index.cjs","sources":["../../../../src/llm/openrouter/index.ts"],"sourcesContent":["import { ChatOpenAI } from '@/llm/openai';\nimport { ChatGenerationChunk } from '@langchain/core/outputs';\nimport { CallbackManagerForLLMRun } from '@langchain/core/callbacks/manager';\nimport { AIMessageChunk as AIMessageChunkClass } from '@langchain/core/messages';\nimport type {\n  FunctionMessageChunk,\n  SystemMessageChunk,\n  HumanMessageChunk,\n  ToolMessageChunk,\n  ChatMessageChunk,\n  AIMessageChunk,\n  BaseMessage,\n} from '@langchain/core/messages';\nimport type {\n  ChatOpenAICallOptions,\n  OpenAIChatInput,\n  OpenAIClient,\n} from '@langchain/openai';\nimport { _convertMessagesToOpenAIParams } from '@/llm/openai/utils';\n\ntype OpenAICompletionParam =\n  OpenAIClient.Chat.Completions.ChatCompletionMessageParam;\n\ntype OpenAIRoleEnum =\n  | 'system'\n  | 'developer'\n  | 'assistant'\n  | 'user'\n  | 'function'\n  | 'tool';\n\nexport interface ChatOpenRouterCallOptions extends ChatOpenAICallOptions {\n  include_reasoning?: boolean;\n  modelKwargs?: OpenAIChatInput['modelKwargs'];\n}\nexport class ChatOpenRouter extends ChatOpenAI {\n  constructor(_fields: Partial<ChatOpenRouterCallOptions>) {\n    const { include_reasoning, modelKwargs = {}, ...fields } = _fields;\n    super({\n      ...fields,\n      modelKwargs: {\n        ...modelKwargs,\n        include_reasoning,\n      },\n    });\n  }\n  static lc_name(): 'LibreChatOpenRouter' {\n    return 'LibreChatOpenRouter';\n  }\n  protected override _convertOpenAIDeltaToBaseMessageChunk(\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    delta: Record<string, any>,\n    rawResponse: OpenAIClient.ChatCompletionChunk,\n    defaultRole?:\n      | 'function'\n      | 'user'\n      | 'system'\n      | 'developer'\n      | 'assistant'\n      | 'tool'\n  ):\n    | AIMessageChunk\n    | HumanMessageChunk\n    | SystemMessageChunk\n    | FunctionMessageChunk\n    | ToolMessageChunk\n    | ChatMessageChunk {\n    const messageChunk = super._convertOpenAIDeltaToBaseMessageChunk(\n      delta,\n      rawResponse,\n      defaultRole\n    );\n    if (delta.reasoning != null) {\n      messageChunk.additional_kwargs.reasoning = delta.reasoning;\n    }\n    if (delta.reasoning_details != null) {\n      messageChunk.additional_kwargs.reasoning_details =\n        delta.reasoning_details;\n    }\n    return messageChunk;\n  }\n\n  async *_streamResponseChunks2(\n    messages: BaseMessage[],\n    options: this['ParsedCallOptions'],\n    runManager?: CallbackManagerForLLMRun\n  ): AsyncGenerator<ChatGenerationChunk> {\n    const messagesMapped: OpenAICompletionParam[] =\n      _convertMessagesToOpenAIParams(messages, this.model, {\n        includeReasoningDetails: true,\n        convertReasoningDetailsToContent: true,\n      });\n\n    const params = {\n      ...this.invocationParams(options, {\n        streaming: true,\n      }),\n      messages: messagesMapped,\n      stream: true as const,\n    };\n    let defaultRole: OpenAIRoleEnum | undefined;\n\n    const streamIterable = await this.completionWithRetry(params, options);\n    let usage: OpenAIClient.Completions.CompletionUsage | undefined;\n\n    // Store reasoning_details keyed by unique identifier to prevent incorrect merging\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const reasoningTextByIndex: Map<number, Record<string, any>> = new Map();\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const reasoningEncryptedById: Map<string, Record<string, any>> = new Map();\n\n    for await (const data of streamIterable) {\n      const choice = data.choices[0] as\n        | Partial<OpenAIClient.Chat.Completions.ChatCompletionChunk.Choice>\n        | undefined;\n      if (data.usage) {\n        usage = data.usage;\n      }\n      if (!choice) {\n        continue;\n      }\n\n      const { delta } = choice;\n      if (!delta) {\n        continue;\n      }\n\n      // Accumulate reasoning_details from each delta\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      const deltaAny = delta as Record<string, any>;\n      // Extract current chunk's reasoning text for streaming (before accumulation)\n      let currentChunkReasoningText = '';\n      if (\n        deltaAny.reasoning_details != null &&\n        Array.isArray(deltaAny.reasoning_details)\n      ) {\n        for (const detail of deltaAny.reasoning_details) {\n          // For encrypted reasoning (thought signatures), store by ID - MUST be separate\n          if (detail.type === 'reasoning.encrypted' && detail.id) {\n            reasoningEncryptedById.set(detail.id, {\n              type: detail.type,\n              id: detail.id,\n              data: detail.data,\n              format: detail.format,\n              index: detail.index,\n            });\n          } else if (detail.type === 'reasoning.text') {\n            // Extract current chunk's text for streaming\n            currentChunkReasoningText += detail.text || '';\n            // For text reasoning, accumulate text by index for final message\n            const idx = detail.index ?? 0;\n            const existing = reasoningTextByIndex.get(idx);\n            if (existing) {\n              // Only append text, keep other fields from first entry\n              existing.text = (existing.text || '') + (detail.text || '');\n            } else {\n              reasoningTextByIndex.set(idx, {\n                type: detail.type,\n                text: detail.text || '',\n                format: detail.format,\n                index: idx,\n              });\n            }\n          }\n        }\n      }\n\n      const chunk = this._convertOpenAIDeltaToBaseMessageChunk(\n        delta,\n        data,\n        defaultRole\n      );\n\n      // For models that send reasoning_details (Gemini style) instead of reasoning (DeepSeek style),\n      // set the current chunk's reasoning text to additional_kwargs.reasoning for streaming\n      if (currentChunkReasoningText && !chunk.additional_kwargs.reasoning) {\n        chunk.additional_kwargs.reasoning = currentChunkReasoningText;\n      }\n\n      // IMPORTANT: Only set reasoning_details on the FINAL chunk to prevent\n      // LangChain's chunk concatenation from corrupting the array\n      // Check if this is the final chunk (has finish_reason)\n      if (choice.finish_reason != null) {\n        // Build properly structured reasoning_details array\n        // Text entries first (but we only need the encrypted ones for thought signatures)\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const finalReasoningDetails: Record<string, any>[] = [\n          ...reasoningTextByIndex.values(),\n          ...reasoningEncryptedById.values(),\n        ];\n\n        if (finalReasoningDetails.length > 0) {\n          chunk.additional_kwargs.reasoning_details = finalReasoningDetails;\n        }\n      } else {\n        // Clear reasoning_details from intermediate chunks to prevent concatenation issues\n        delete chunk.additional_kwargs.reasoning_details;\n      }\n\n      defaultRole = delta.role ?? defaultRole;\n      const newTokenIndices = {\n        prompt: options.promptIndex ?? 0,\n        completion: choice.index ?? 0,\n      };\n      if (typeof chunk.content !== 'string') {\n        // eslint-disable-next-line no-console\n        console.log(\n          '[WARNING]: Received non-string content from OpenAI. This is currently not supported.'\n        );\n        continue;\n      }\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      const generationInfo: Record<string, any> = { ...newTokenIndices };\n      if (choice.finish_reason != null) {\n        generationInfo.finish_reason = choice.finish_reason;\n        generationInfo.system_fingerprint = data.system_fingerprint;\n        generationInfo.model_name = data.model;\n        generationInfo.service_tier = data.service_tier;\n      }\n      if (this.logprobs == true) {\n        generationInfo.logprobs = choice.logprobs;\n      }\n      const generationChunk = new ChatGenerationChunk({\n        message: chunk,\n        text: chunk.content,\n        generationInfo,\n      });\n      yield generationChunk;\n      if (this._lc_stream_delay != null) {\n        await new Promise((resolve) =>\n          setTimeout(resolve, this._lc_stream_delay)\n        );\n      }\n      await runManager?.handleLLMNewToken(\n        generationChunk.text || '',\n        newTokenIndices,\n        undefined,\n        undefined,\n        undefined,\n        { chunk: generationChunk }\n      );\n    }\n    if (usage) {\n      const inputTokenDetails = {\n        ...(usage.prompt_tokens_details?.audio_tokens != null && {\n          audio: usage.prompt_tokens_details.audio_tokens,\n        }),\n        ...(usage.prompt_tokens_details?.cached_tokens != null && {\n          cache_read: usage.prompt_tokens_details.cached_tokens,\n        }),\n      };\n      const outputTokenDetails = {\n        ...(usage.completion_tokens_details?.audio_tokens != null && {\n          audio: usage.completion_tokens_details.audio_tokens,\n        }),\n        ...(usage.completion_tokens_details?.reasoning_tokens != null && {\n          reasoning: usage.completion_tokens_details.reasoning_tokens,\n        }),\n      };\n      const generationChunk = new ChatGenerationChunk({\n        message: new AIMessageChunkClass({\n          content: '',\n          response_metadata: {\n            usage: { ...usage },\n          },\n          usage_metadata: {\n            input_tokens: usage.prompt_tokens,\n            output_tokens: usage.completion_tokens,\n            total_tokens: usage.total_tokens,\n            ...(Object.keys(inputTokenDetails).length > 0 && {\n              input_token_details: inputTokenDetails,\n            }),\n            ...(Object.keys(outputTokenDetails).length > 0 && {\n              output_token_details: outputTokenDetails,\n            }),\n          },\n        }),\n        text: '',\n      });\n      yield generationChunk;\n      if (this._lc_stream_delay != null) {\n        await new Promise((resolve) =>\n          setTimeout(resolve, this._lc_stream_delay)\n        );\n      }\n    }\n    if (options.signal?.aborted === true) {\n      throw new Error('AbortError');\n    }\n  }\n}\n"],"names":["ChatOpenAI","messages","_convertMessagesToOpenAIParams","ChatGenerationChunk","AIMessageChunkClass"],"mappings":";;;;;;;AAmCM,MAAO,cAAe,SAAQA,gBAAU,CAAA;AAC5C,IAAA,WAAA,CAAY,OAA2C,EAAA;AACrD,QAAA,MAAM,EAAE,iBAAiB,EAAE,WAAW,GAAG,EAAE,EAAE,GAAG,MAAM,EAAE,GAAG,OAAO;AAClE,QAAA,KAAK,CAAC;AACJ,YAAA,GAAG,MAAM;AACT,YAAA,WAAW,EAAE;AACX,gBAAA,GAAG,WAAW;gBACd,iBAAiB;AAClB,aAAA;AACF,SAAA,CAAC;;AAEJ,IAAA,OAAO,OAAO,GAAA;AACZ,QAAA,OAAO,qBAAqB;;IAEX,qCAAqC;;IAEtD,KAA0B,EAC1B,WAA6C,EAC7C,WAMU,EAAA;AAQV,QAAA,MAAM,YAAY,GAAG,KAAK,CAAC,qCAAqC,CAC9D,KAAK,EACL,WAAW,EACX,WAAW,CACZ;AACD,QAAA,IAAI,KAAK,CAAC,SAAS,IAAI,IAAI,EAAE;YAC3B,YAAY,CAAC,iBAAiB,CAAC,SAAS,GAAG,KAAK,CAAC,SAAS;;AAE5D,QAAA,IAAI,KAAK,CAAC,iBAAiB,IAAI,IAAI,EAAE;YACnC,YAAY,CAAC,iBAAiB,CAAC,iBAAiB;gBAC9C,KAAK,CAAC,iBAAiB;;AAE3B,QAAA,OAAO,YAAY;;IAGrB,OAAO,sBAAsB,CAC3BC,UAAuB,EACvB,OAAkC,EAClC,UAAqC,EAAA;QAErC,MAAM,cAAc,GAClBC,sCAA8B,CAACD,UAAQ,EAAE,IAAI,CAAC,KAAK,EAAE;AACnD,YAAA,uBAAuB,EAAE,IAAI;AAC7B,YAAA,gCAAgC,EAAE,IAAI;AACvC,SAAA,CAAC;AAEJ,QAAA,MAAM,MAAM,GAAG;AACb,YAAA,GAAG,IAAI,CAAC,gBAAgB,CAAC,OAAO,EAAE;AAChC,gBAAA,SAAS,EAAE,IAAI;aAChB,CAAC;AACF,YAAA,QAAQ,EAAE,cAAc;AACxB,YAAA,MAAM,EAAE,IAAa;SACtB;AACD,QAAA,IAAI,WAAuC;QAE3C,MAAM,cAAc,GAAG,MAAM,IAAI,CAAC,mBAAmB,CAAC,MAAM,EAAE,OAAO,CAAC;AACtE,QAAA,IAAI,KAA2D;;;AAI/D,QAAA,MAAM,oBAAoB,GAAqC,IAAI,GAAG,EAAE;;AAExE,QAAA,MAAM,sBAAsB,GAAqC,IAAI,GAAG,EAAE;AAE1E,QAAA,WAAW,MAAM,IAAI,IAAI,cAAc,EAAE;YACvC,MAAM,MAAM,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAEhB;AACb,YAAA,IAAI,IAAI,CAAC,KAAK,EAAE;AACd,gBAAA,KAAK,GAAG,IAAI,CAAC,KAAK;;YAEpB,IAAI,CAAC,MAAM,EAAE;gBACX;;AAGF,YAAA,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM;YACxB,IAAI,CAAC,KAAK,EAAE;gBACV;;;;YAKF,MAAM,QAAQ,GAAG,KAA4B;;YAE7C,IAAI,yBAAyB,GAAG,EAAE;AAClC,YAAA,IACE,QAAQ,CAAC,iBAAiB,IAAI,IAAI;gBAClC,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,iBAAiB,CAAC,EACzC;AACA,gBAAA,KAAK,MAAM,MAAM,IAAI,QAAQ,CAAC,iBAAiB,EAAE;;oBAE/C,IAAI,MAAM,CAAC,IAAI,KAAK,qBAAqB,IAAI,MAAM,CAAC,EAAE,EAAE;AACtD,wBAAA,sBAAsB,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,EAAE;4BACpC,IAAI,EAAE,MAAM,CAAC,IAAI;4BACjB,EAAE,EAAE,MAAM,CAAC,EAAE;4BACb,IAAI,EAAE,MAAM,CAAC,IAAI;4BACjB,MAAM,EAAE,MAAM,CAAC,MAAM;4BACrB,KAAK,EAAE,MAAM,CAAC,KAAK;AACpB,yBAAA,CAAC;;AACG,yBAAA,IAAI,MAAM,CAAC,IAAI,KAAK,gBAAgB,EAAE;;AAE3C,wBAAA,yBAAyB,IAAI,MAAM,CAAC,IAAI,IAAI,EAAE;;AAE9C,wBAAA,MAAM,GAAG,GAAG,MAAM,CAAC,KAAK,IAAI,CAAC;wBAC7B,MAAM,QAAQ,GAAG,oBAAoB,CAAC,GAAG,CAAC,GAAG,CAAC;wBAC9C,IAAI,QAAQ,EAAE;;AAEZ,4BAAA,QAAQ,CAAC,IAAI,GAAG,CAAC,QAAQ,CAAC,IAAI,IAAI,EAAE,KAAK,MAAM,CAAC,IAAI,IAAI,EAAE,CAAC;;6BACtD;AACL,4BAAA,oBAAoB,CAAC,GAAG,CAAC,GAAG,EAAE;gCAC5B,IAAI,EAAE,MAAM,CAAC,IAAI;AACjB,gCAAA,IAAI,EAAE,MAAM,CAAC,IAAI,IAAI,EAAE;gCACvB,MAAM,EAAE,MAAM,CAAC,MAAM;AACrB,gCAAA,KAAK,EAAE,GAAG;AACX,6BAAA,CAAC;;;;;AAMV,YAAA,MAAM,KAAK,GAAG,IAAI,CAAC,qCAAqC,CACtD,KAAK,EACL,IAAI,EACJ,WAAW,CACZ;;;YAID,IAAI,yBAAyB,IAAI,CAAC,KAAK,CAAC,iBAAiB,CAAC,SAAS,EAAE;AACnE,gBAAA,KAAK,CAAC,iBAAiB,CAAC,SAAS,GAAG,yBAAyB;;;;;AAM/D,YAAA,IAAI,MAAM,CAAC,aAAa,IAAI,IAAI,EAAE;;;;AAIhC,gBAAA,MAAM,qBAAqB,GAA0B;oBACnD,GAAG,oBAAoB,CAAC,MAAM,EAAE;oBAChC,GAAG,sBAAsB,CAAC,MAAM,EAAE;iBACnC;AAED,gBAAA,IAAI,qBAAqB,CAAC,MAAM,GAAG,CAAC,EAAE;AACpC,oBAAA,KAAK,CAAC,iBAAiB,CAAC,iBAAiB,GAAG,qBAAqB;;;iBAE9D;;AAEL,gBAAA,OAAO,KAAK,CAAC,iBAAiB,CAAC,iBAAiB;;AAGlD,YAAA,WAAW,GAAG,KAAK,CAAC,IAAI,IAAI,WAAW;AACvC,YAAA,MAAM,eAAe,GAAG;AACtB,gBAAA,MAAM,EAAE,OAAO,CAAC,WAAW,IAAI,CAAC;AAChC,gBAAA,UAAU,EAAE,MAAM,CAAC,KAAK,IAAI,CAAC;aAC9B;AACD,YAAA,IAAI,OAAO,KAAK,CAAC,OAAO,KAAK,QAAQ,EAAE;;AAErC,gBAAA,OAAO,CAAC,GAAG,CACT,sFAAsF,CACvF;gBACD;;;AAGF,YAAA,MAAM,cAAc,GAAwB,EAAE,GAAG,eAAe,EAAE;AAClE,YAAA,IAAI,MAAM,CAAC,aAAa,IAAI,IAAI,EAAE;AAChC,gBAAA,cAAc,CAAC,aAAa,GAAG,MAAM,CAAC,aAAa;AACnD,gBAAA,cAAc,CAAC,kBAAkB,GAAG,IAAI,CAAC,kBAAkB;AAC3D,gBAAA,cAAc,CAAC,UAAU,GAAG,IAAI,CAAC,KAAK;AACtC,gBAAA,cAAc,CAAC,YAAY,GAAG,IAAI,CAAC,YAAY;;AAEjD,YAAA,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;AACzB,gBAAA,cAAc,CAAC,QAAQ,GAAG,MAAM,CAAC,QAAQ;;AAE3C,YAAA,MAAM,eAAe,GAAG,IAAIE,2BAAmB,CAAC;AAC9C,gBAAA,OAAO,EAAE,KAAK;gBACd,IAAI,EAAE,KAAK,CAAC,OAAO;gBACnB,cAAc;AACf,aAAA,CAAC;AACF,YAAA,MAAM,eAAe;AACrB,YAAA,IAAI,IAAI,CAAC,gBAAgB,IAAI,IAAI,EAAE;AACjC,gBAAA,MAAM,IAAI,OAAO,CAAC,CAAC,OAAO,KACxB,UAAU,CAAC,OAAO,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAC3C;;YAEH,MAAM,UAAU,EAAE,iBAAiB,CACjC,eAAe,CAAC,IAAI,IAAI,EAAE,EAC1B,eAAe,EACf,SAAS,EACT,SAAS,EACT,SAAS,EACT,EAAE,KAAK,EAAE,eAAe,EAAE,CAC3B;;QAEH,IAAI,KAAK,EAAE;AACT,YAAA,MAAM,iBAAiB,GAAG;gBACxB,IAAI,KAAK,CAAC,qBAAqB,EAAE,YAAY,IAAI,IAAI,IAAI;AACvD,oBAAA,KAAK,EAAE,KAAK,CAAC,qBAAqB,CAAC,YAAY;iBAChD,CAAC;gBACF,IAAI,KAAK,CAAC,qBAAqB,EAAE,aAAa,IAAI,IAAI,IAAI;AACxD,oBAAA,UAAU,EAAE,KAAK,CAAC,qBAAqB,CAAC,aAAa;iBACtD,CAAC;aACH;AACD,YAAA,MAAM,kBAAkB,GAAG;gBACzB,IAAI,KAAK,CAAC,yBAAyB,EAAE,YAAY,IAAI,IAAI,IAAI;AAC3D,oBAAA,KAAK,EAAE,KAAK,CAAC,yBAAyB,CAAC,YAAY;iBACpD,CAAC;gBACF,IAAI,KAAK,CAAC,yBAAyB,EAAE,gBAAgB,IAAI,IAAI,IAAI;AAC/D,oBAAA,SAAS,EAAE,KAAK,CAAC,yBAAyB,CAAC,gBAAgB;iBAC5D,CAAC;aACH;AACD,YAAA,MAAM,eAAe,GAAG,IAAIA,2BAAmB,CAAC;gBAC9C,OAAO,EAAE,IAAIC,uBAAmB,CAAC;AAC/B,oBAAA,OAAO,EAAE,EAAE;AACX,oBAAA,iBAAiB,EAAE;AACjB,wBAAA,KAAK,EAAE,EAAE,GAAG,KAAK,EAAE;AACpB,qBAAA;AACD,oBAAA,cAAc,EAAE;wBACd,YAAY,EAAE,KAAK,CAAC,aAAa;wBACjC,aAAa,EAAE,KAAK,CAAC,iBAAiB;wBACtC,YAAY,EAAE,KAAK,CAAC,YAAY;wBAChC,IAAI,MAAM,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC,MAAM,GAAG,CAAC,IAAI;AAC/C,4BAAA,mBAAmB,EAAE,iBAAiB;yBACvC,CAAC;wBACF,IAAI,MAAM,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC,MAAM,GAAG,CAAC,IAAI;AAChD,4BAAA,oBAAoB,EAAE,kBAAkB;yBACzC,CAAC;AACH,qBAAA;iBACF,CAAC;AACF,gBAAA,IAAI,EAAE,EAAE;AACT,aAAA,CAAC;AACF,YAAA,MAAM,eAAe;AACrB,YAAA,IAAI,IAAI,CAAC,gBAAgB,IAAI,IAAI,EAAE;AACjC,gBAAA,MAAM,IAAI,OAAO,CAAC,CAAC,OAAO,KACxB,UAAU,CAAC,OAAO,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAC3C;;;QAGL,IAAI,OAAO,CAAC,MAAM,EAAE,OAAO,KAAK,IAAI,EAAE;AACpC,YAAA,MAAM,IAAI,KAAK,CAAC,YAAY,CAAC;;;AAGlC;;;;"}